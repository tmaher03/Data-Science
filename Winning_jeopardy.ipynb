{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Winning Jeopardy\n",
    "This project investigates similarity between historical jeopardy answers and questions to see if there are any relationships that could be exploited and used as a study guide to improve a contestants chances of winning. \n",
    "\n",
    "The data set is the first 20,000 rows from a data set posted on reddit which can be found here: https://www.reddit.com/r/datasets/comments/1uyd0t/200000_jeopardy_questions_in_a_json_file/\n",
    "\n",
    "Two main questions we will be trying to answer are:\n",
    "1) How often do questions contain hints about the answer?\n",
    "2) How often are questions repeated over time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number    Air Date      Round                         Category  Value  \\\n",
       "0         4680  2004-12-31  Jeopardy!                          HISTORY   $200   \n",
       "1         4680  2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES   $200   \n",
       "2         4680  2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...   $200   \n",
       "3         4680  2004-12-31  Jeopardy!                 THE COMPANY LINE   $200   \n",
       "4         4680  2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES   $200   \n",
       "\n",
       "                                            Question      Answer  \n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus  \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe  \n",
       "2  The city of Yuma in this state has a record av...     Arizona  \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's  \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "\n",
    "# Read in data\n",
    "jeopardy = pd.read_csv(\"jeopardy.csv\")\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clean and prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Show Number', ' Air Date', ' Round', ' Category', ' Value',\n",
       "       ' Question', ' Answer'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# investigate column names\n",
    "jeopardy.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Remove spaces from the column names\n",
    "jeopardy.columns = [col.strip() for col in jeopardy.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "Show Number    19999 non-null int64\n",
      "Air Date       19999 non-null object\n",
      "Round          19999 non-null object\n",
      "Category       19999 non-null object\n",
      "Value          19999 non-null object\n",
      "Question       19999 non-null object\n",
      "Answer         19999 non-null object\n",
      "dtypes: int64(1), object(6)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "# Check data types and check for null values\n",
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Convert date column to datetime format\n",
    "jeopardy['Air Date'] = pd.to_datetime(jeopardy['Air Date'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 19999 entries, 0 to 19998\n",
      "Data columns (total 7 columns):\n",
      "Show Number    19999 non-null int64\n",
      "Air Date       19999 non-null datetime64[ns]\n",
      "Round          19999 non-null object\n",
      "Category       19999 non-null object\n",
      "Value          19999 non-null object\n",
      "Question       19999 non-null object\n",
      "Answer         19999 non-null object\n",
      "dtypes: datetime64[ns](1), int64(1), object(5)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "jeopardy.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "On order to analyze the words in the question and answer columns we need to remove all punctuation to normalize them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Show Number</th>\n",
       "      <th>Air Date</th>\n",
       "      <th>Round</th>\n",
       "      <th>Category</th>\n",
       "      <th>Value</th>\n",
       "      <th>Question</th>\n",
       "      <th>Answer</th>\n",
       "      <th>clean_question</th>\n",
       "      <th>clean_answer</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>HISTORY</td>\n",
       "      <td>$200</td>\n",
       "      <td>For the last 8 years of his life, Galileo was ...</td>\n",
       "      <td>Copernicus</td>\n",
       "      <td>for the last 8 years of his life galileo was u...</td>\n",
       "      <td>copernicus</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>ESPN's TOP 10 ALL-TIME ATHLETES</td>\n",
       "      <td>$200</td>\n",
       "      <td>No. 2: 1912 Olympian; football star at Carlisl...</td>\n",
       "      <td>Jim Thorpe</td>\n",
       "      <td>no 2 1912 olympian football star at carlisle i...</td>\n",
       "      <td>jim thorpe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EVERYBODY TALKS ABOUT IT...</td>\n",
       "      <td>$200</td>\n",
       "      <td>The city of Yuma in this state has a record av...</td>\n",
       "      <td>Arizona</td>\n",
       "      <td>the city of yuma in this state has a record av...</td>\n",
       "      <td>arizona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>THE COMPANY LINE</td>\n",
       "      <td>$200</td>\n",
       "      <td>In 1963, live on \"The Art Linkletter Show\", th...</td>\n",
       "      <td>McDonald's</td>\n",
       "      <td>in 1963 live on the art linkletter show this c...</td>\n",
       "      <td>mcdonalds</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4680</td>\n",
       "      <td>2004-12-31</td>\n",
       "      <td>Jeopardy!</td>\n",
       "      <td>EPITAPHS &amp; TRIBUTES</td>\n",
       "      <td>$200</td>\n",
       "      <td>Signer of the Dec. of Indep., framer of the Co...</td>\n",
       "      <td>John Adams</td>\n",
       "      <td>signer of the dec of indep framer of the const...</td>\n",
       "      <td>john adams</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Show Number   Air Date      Round                         Category Value  \\\n",
       "0         4680 2004-12-31  Jeopardy!                          HISTORY  $200   \n",
       "1         4680 2004-12-31  Jeopardy!  ESPN's TOP 10 ALL-TIME ATHLETES  $200   \n",
       "2         4680 2004-12-31  Jeopardy!      EVERYBODY TALKS ABOUT IT...  $200   \n",
       "3         4680 2004-12-31  Jeopardy!                 THE COMPANY LINE  $200   \n",
       "4         4680 2004-12-31  Jeopardy!              EPITAPHS & TRIBUTES  $200   \n",
       "\n",
       "                                            Question      Answer  \\\n",
       "0  For the last 8 years of his life, Galileo was ...  Copernicus   \n",
       "1  No. 2: 1912 Olympian; football star at Carlisl...  Jim Thorpe   \n",
       "2  The city of Yuma in this state has a record av...     Arizona   \n",
       "3  In 1963, live on \"The Art Linkletter Show\", th...  McDonald's   \n",
       "4  Signer of the Dec. of Indep., framer of the Co...  John Adams   \n",
       "\n",
       "                                      clean_question clean_answer  \n",
       "0  for the last 8 years of his life galileo was u...   copernicus  \n",
       "1  no 2 1912 olympian football star at carlisle i...   jim thorpe  \n",
       "2  the city of yuma in this state has a record av...      arizona  \n",
       "3  in 1963 live on the art linkletter show this c...    mcdonalds  \n",
       "4  signer of the dec of indep framer of the const...   john adams  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def normalize(str_):\n",
    "    \"\"\"\n",
    "    Function takes in a string and removes all punctuation.\n",
    "    \"\"\"\n",
    "    str_ = re.sub('[^\\w\\s]','',str_.lower())\n",
    "    \n",
    "    return str_\n",
    "\n",
    "# Using the function above, clean the question and answer columns\n",
    "# in the data set.\n",
    "jeopardy['clean_question'] = jeopardy['Question'].apply(normalize)\n",
    "jeopardy['clean_answer'] = jeopardy['Answer'].apply(normalize)\n",
    "\n",
    "# Check data\n",
    "jeopardy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value column is also problematic because it is in string format and has punctuation in it. We will write a function to clean that as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create function to clean the Value column\n",
    "\n",
    "def norm_value(value):\n",
    "    \"\"\"\n",
    "    Function takes in a string, removes '$' and ',' and casts string to an integer\n",
    "    \"\"\"\n",
    "    \n",
    "    if value == 'None':\n",
    "        value = 0\n",
    "    else:\n",
    "        value = value.strip('\\$').replace(',','')\n",
    "        \n",
    "    return int(value)\n",
    "\n",
    "# Apply function and create new column\n",
    "jeopardy['clean_value'] = jeopardy['Value'].apply(norm_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis\n",
    "### Repeat words\n",
    "Let's start with investigating whether it is possible to figure out the answer to a question from the words in the question. We will investigate how often words from the question are repeated in the answer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def repeat_words(row):\n",
    "    \"\"\"\n",
    "    Function takes in a dataframe row and converts the clean_answer and \n",
    "    clean_question columns to lists. It then removes the word 'The' from \n",
    "    the beginning of the answer and returns the proportion of answer words\n",
    "    that are in the question.\n",
    "    \"\"\"\n",
    "    \n",
    "    split_answer = row['clean_answer'].split()\n",
    "    split_question = row['clean_question'].split()\n",
    "    \n",
    "    # Counter to count how many words are in both question and answer\n",
    "    match_count = 0\n",
    "    \n",
    "    # Remove the word 'The'\n",
    "    if 'the' in split_answer:\n",
    "        split_answer.remove('the')\n",
    "    \n",
    "    # Return proportion of matched words\n",
    "    if len(split_answer) == 0:\n",
    "        return 0     \n",
    "    else:\n",
    "        for item in split_answer:\n",
    "            if item in split_question:\n",
    "                match_count += 1                \n",
    "    return (match_count / len(split_answer))\n",
    "\n",
    "# Apply to dataframe\n",
    "jeopardy['answer_in_question'] = jeopardy.apply(repeat_words, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.05900196524977763"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate the mean proportion of repeat words\n",
    "jeopardy['answer_in_question'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000      124\n",
       "0.875000        1\n",
       "0.800000        2\n",
       "0.750000       17\n",
       "0.666667      104\n",
       "0.600000        9\n",
       "0.571429        2\n",
       "0.500000     1448\n",
       "0.444444        1\n",
       "0.428571        2\n",
       "0.400000       26\n",
       "0.350000        1\n",
       "0.333333      494\n",
       "0.300000        2\n",
       "0.285714        7\n",
       "0.250000      155\n",
       "0.200000       68\n",
       "0.181818        2\n",
       "0.166667       27\n",
       "0.142857       21\n",
       "0.125000        9\n",
       "0.111111        2\n",
       "0.000000    17475\n",
       "Name: answer_in_question, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate how many questions have relatively high proportion of repeat words\n",
    "jeopardy['answer_in_question'].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.08535426771338567"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Proportion of answers with 50% or more words in the question\n",
    "jeopardy['answer_in_question'][jeopardy['answer_in_question'] >= 0.5].count() / jeopardy['answer_in_question'].count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It appears 8.5% of the questions have half or more of the words in the question repeated in the answer. The mean number of repeat words is 5.9%. Since it's only a small number of answers that have repeat words, there are some answers with a significantly high percentage of repeat words. This is a significant enough percentage to investigate as the type of question could be identifiable and could inform studying. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repeat questions\n",
    "Next let's see how often questions are repeat questions. We only have 10% of the total data but we will try and see what conclusions we can draw. We will look at how often words are reused across questions over time. To focus on meaningful words and ignore small common words like articles, we will just focus on words with six or more characters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Sort rows by air date\n",
    "jeopardy_sorted = jeopardy.sort_values('Air Date')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6649036076777254"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create an empty set to house all the unique words used\n",
    "terms_used = set()\n",
    "\n",
    "def repeat_questions(row):\n",
    "    \"\"\"\n",
    "    Function takes in a row and calculates the proportion of words\n",
    "    in the clean_question column which are repeated in the terms_used\n",
    "    set. If the words are not present in terms_used, they are added \n",
    "    to the set. \n",
    "    \n",
    "    Function returns the proportion of words repeated as a float.\n",
    "    \"\"\"\n",
    "    \n",
    "    split_question = row['clean_question'].split(' ')\n",
    "    split_question = [word for word in split_question if len(word) > 6]\n",
    "        \n",
    "    match_count = 0\n",
    "    \n",
    "    for word in split_question:  \n",
    "        if word in terms_used:\n",
    "            match_count += 1\n",
    "        else:\n",
    "            terms_used.add(word)\n",
    "                \n",
    "    if len(split_question) > 0:\n",
    "        return match_count / len(split_question)\n",
    "\n",
    "# Apply function to sorted df\n",
    "jeopardy_sorted['question_overlap'] = jeopardy_sorted.apply(repeat_questions, axis=1)\n",
    "# calculate mean proportion of repeated words\n",
    "jeopardy_sorted['question_overlap'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.000000    6853\n",
       "0.950000       1\n",
       "0.923077       1\n",
       "0.916667       3\n",
       "0.909091       4\n",
       "0.900000       4\n",
       "0.888889       4\n",
       "0.875000      21\n",
       "0.866667       1\n",
       "0.857143      77\n",
       "0.846154       1\n",
       "0.833333     228\n",
       "0.818182       7\n",
       "0.800000     648\n",
       "0.785714       1\n",
       "0.777778      14\n",
       "0.769231       2\n",
       "0.764706       1\n",
       "0.750000    1320\n",
       "0.733333       2\n",
       "0.727273      13\n",
       "0.714286      79\n",
       "0.705882       1\n",
       "0.700000      10\n",
       "0.692308       7\n",
       "0.666667    2040\n",
       "0.642857       2\n",
       "0.636364       5\n",
       "0.625000      30\n",
       "0.615385       9\n",
       "0.600000     546\n",
       "0.583333       3\n",
       "0.571429      58\n",
       "0.555556      14\n",
       "0.545455       6\n",
       "0.533333       1\n",
       "0.500000    2725\n",
       "0.461538       3\n",
       "0.454545       5\n",
       "0.444444       7\n",
       "0.428571      28\n",
       "0.416667       2\n",
       "0.400000     255\n",
       "0.384615       2\n",
       "0.375000      11\n",
       "0.363636       2\n",
       "0.333333    1014\n",
       "0.285714      10\n",
       "0.250000     391\n",
       "0.222222       1\n",
       "0.200000      95\n",
       "0.166667      20\n",
       "0.142857       5\n",
       "Name: question_overlap, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calculate how often proportions above 0 appear in the data set\n",
    "jeopardy_sorted['question_overlap'][jeopardy_sorted['question_overlap'] > 0].value_counts().sort_index(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "There are over 6000 questions where all of the words used over six characters reappear in other questions. This is quite a significant number considering we only have 20000 rows. The average number of repeated words is 66% of the words in a question over six characters. It seems that studying old questions would be highly valuable to a contestant. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Repeat words in high value questions\n",
    "We will now look at how often words that are in the terms_used set are in high value (over $800) questions. We will start with labeling rows as high value or not and then "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create function to label high value and low value questions in a new row\n",
    "def q_value(row):\n",
    "    if row['clean_value'] > 800:\n",
    "        value = 1\n",
    "    else:\n",
    "        value = 0\n",
    "    \n",
    "    return value\n",
    "\n",
    "# Apply function and create labels\n",
    "jeopardy_sorted['high_value'] = jeopardy_sorted.apply(q_value, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create function to count the number of times a word occurs in high and low\n",
    "# value questions in the data set.\n",
    "def word_value(word):\n",
    "    \"\"\"\n",
    "    Function takes in a word and returns the number of times the word occurs in\n",
    "    both high value and low value questions (function returns to values).\n",
    "    \"\"\"\n",
    "    low_count = 0\n",
    "    high_count = 0\n",
    "    \n",
    "    for i, row in jeopardy_sorted.iterrows():\n",
    "        split_question = row['clean_question'].split()\n",
    "        if word in split_question:\n",
    "            if row['high_value'] == 1:\n",
    "                high_count += 1\n",
    "            else:\n",
    "                low_count += 1\n",
    "                \n",
    "    return high_count, low_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate chi squared value for each word\n",
    "For efficiency purposes, we will sample 10 words from our set of words stored as terms_used. We can then calculate the number of times the word occurs in both high and low value questions and calculate a chi squared score using the proportion of high and low value questions as our expected values. If we have a high enough chi squared score we can see which questions are more valuable to study."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Randomly sample 10 words from terms_used set\n",
    "import random\n",
    "comparison_terms = random.sample(terms_used, 10)\n",
    "observed_expected = []\n",
    "\n",
    "# Iterate through sample list and feed into word_value function defined above to\n",
    "# return the counts of the word in both high and low value questions\n",
    "for word in comparison_terms:\n",
    "    observed_expected.append(word_value(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.4448774816612795, pvalue=0.5047776487545996),\n",
       " Power_divergenceResult(statistic=1.205888538380652, pvalue=0.27214791766902047),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.803925692253768, pvalue=0.3699222378079571),\n",
       " Power_divergenceResult(statistic=4.97558423439135, pvalue=0.025707519787911092),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469),\n",
       " Power_divergenceResult(statistic=0.401962846126884, pvalue=0.5260772985705469)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import chisquare\n",
    "# Get the total counts of both high value and low value questions in the data\n",
    "high_value_count = jeopardy_sorted[jeopardy_sorted['high_value'] == 1].shape[0]\n",
    "low_value_count = jeopardy_sorted[jeopardy_sorted['high_value'] == 0].shape[0]\n",
    "\n",
    "# Empty list to store the chi_squared values.\n",
    "chi_squared = []\n",
    "\n",
    "# Iterate through observed counts, sum the observed counts, calculate the \n",
    "# proportion of observations to the total number of questions; then calculate\n",
    "# the expected proportions by multiplying the total proportion by the number of \n",
    "# high value questions and the number of low value questions.\n",
    "for observation in observed_expected:\n",
    "    total = sum(observation)\n",
    "    total_prop = total / jeopardy_sorted.shape[0]\n",
    "    high_value_expected = total_prop * high_value_count\n",
    "    low_value_expected = total_prop * low_value_count\n",
    "    expected = (high_value_expected,low_value_expected)\n",
    "    \n",
    "    values = chisquare(observation, expected)\n",
    "    chi_squared.append(values)\n",
    "    \n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "It appears only one of the ten results has a significant P-value (0.0257) and a chi value of almost 5 (4.975). But if the sample is representative of the whole population then perhaps up to 10% of words may have a significant chisquare and P-value. Let's see if we can improve these scores by looking for high frequency words in particular."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19401"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Making a frequency table for the words would take to long because we have a lot\n",
    "# of words!\n",
    "terms_used = list(terms_used)\n",
    "len(terms_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['strongest',\n",
       " 'wharton',\n",
       " 'medicine',\n",
       " 'bergenbelsen',\n",
       " 'hrefhttpwwwjarchivecommedia20100706_dj_14jpg',\n",
       " 'huizong',\n",
       " 'grandmother',\n",
       " 'berserk',\n",
       " 'designate',\n",
       " 'kendall']"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Some of the words appear to actually be image files.\n",
    "terms_used[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1208\n"
     ]
    }
   ],
   "source": [
    "# The image files have very long names so we can look for words with over 25 characters.\n",
    "count = 0\n",
    "for word in terms_used:\n",
    "    \n",
    "    if len(word) > 25:\n",
    "        count += 1\n",
    "        \n",
    "print(count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18193"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove words over 25 characters to clear out image files\n",
    "terms_used = [word for word in terms_used if len(word) <= 25]\n",
    "len(terms_used)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19325    None\n",
       "19301    None\n",
       "19302    None\n",
       "19303    None\n",
       "19304    None\n",
       "19305    None\n",
       "19306    None\n",
       "19307    None\n",
       "19308    None\n",
       "19309    None\n",
       "19310    None\n",
       "19311    None\n",
       "19312    None\n",
       "19313    None\n",
       "19314    None\n",
       "19315    None\n",
       "19316    None\n",
       "19317    None\n",
       "19318    None\n",
       "19319    None\n",
       "19320    None\n",
       "19321    None\n",
       "19322    None\n",
       "19323    None\n",
       "19300    None\n",
       "19324    None\n",
       "19299    None\n",
       "19297    None\n",
       "19274    None\n",
       "19275    None\n",
       "         ... \n",
       "1973     None\n",
       "1974     None\n",
       "1959     None\n",
       "1958     None\n",
       "1957     None\n",
       "1956     None\n",
       "1934     None\n",
       "1935     None\n",
       "1936     None\n",
       "1937     None\n",
       "1938     None\n",
       "1939     None\n",
       "1940     None\n",
       "1941     None\n",
       "1942     None\n",
       "1943     None\n",
       "1932     None\n",
       "1944     None\n",
       "1946     None\n",
       "1947     None\n",
       "1948     None\n",
       "1949     None\n",
       "1950     None\n",
       "1951     None\n",
       "1952     None\n",
       "1953     None\n",
       "1954     None\n",
       "1955     None\n",
       "1945     None\n",
       "1922     None\n",
       "Name: clean_question, Length: 19999, dtype: object"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty dictionary\n",
    "for word in terms_used:\n",
    "    word_freq[word] = 0\n",
    "    \n",
    "# Create frequency table\n",
    "def word_count(question):\n",
    "    split_question = question.split()\n",
    "    \n",
    "    for word in terms_used:\n",
    "        if word in split_question:\n",
    "            word_freq[word] += 1\n",
    "\n",
    "jeopardy_sorted['clean_question'].apply(word_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create dataframe from frequency table\n",
    "word_freq_df = pd.DataFrame.from_dict(word_freq, orient='index')\n",
    "word_freq_df.rename(columns={0:'count'}, inplace=True)\n",
    "# Store 20 most common words as a list\n",
    "common_words = list(word_freq_df['count'].sort_values(ascending=False)[:20].index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now rerun our chi squared calculations using the 20 most common words in terms_used. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Power_divergenceResult(statistic=0.29967829483482744, pvalue=0.5840841713114313),\n",
       " Power_divergenceResult(statistic=0.4938111242657224, pvalue=0.4822321568398581),\n",
       " Power_divergenceResult(statistic=0.22592591114717697, pvalue=0.6345612982626103),\n",
       " Power_divergenceResult(statistic=1.9084254764809114, pvalue=0.16713826420471323),\n",
       " Power_divergenceResult(statistic=15.028296538003147, pvalue=0.00010591119029347305),\n",
       " Power_divergenceResult(statistic=0.36956355622281933, pvalue=0.5432422635312689),\n",
       " Power_divergenceResult(statistic=1.9892622715198827, pvalue=0.15841803672554888),\n",
       " Power_divergenceResult(statistic=1.4521478773041714, pvalue=0.22818361990918334),\n",
       " Power_divergenceResult(statistic=4.4934633334396965, pvalue=0.03402468062121473),\n",
       " Power_divergenceResult(statistic=2.6950209285044178, pvalue=0.10066216730100558),\n",
       " Power_divergenceResult(statistic=0.08036666360833383, pvalue=0.7768011333475542),\n",
       " Power_divergenceResult(statistic=0.0027964365481966506, pvalue=0.9578264488892704),\n",
       " Power_divergenceResult(statistic=3.4193064786286467, pvalue=0.06443807841398486),\n",
       " Power_divergenceResult(statistic=16.1398795828231, pvalue=5.883208699870318e-05),\n",
       " Power_divergenceResult(statistic=4.644947440199665, pvalue=0.031145090879057265),\n",
       " Power_divergenceResult(statistic=0.0006846341565692503, pvalue=0.9791253217871299),\n",
       " Power_divergenceResult(statistic=22.92015726204268, pvalue=1.6887164902326845e-06),\n",
       " Power_divergenceResult(statistic=0.41769790572413584, pvalue=0.5180879853877616),\n",
       " Power_divergenceResult(statistic=1.771905597365104, pvalue=0.1831464220877349),\n",
       " Power_divergenceResult(statistic=6.034956335550907, pvalue=0.014025297767102603)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize empty list to hold observed high/low value counts\n",
    "observed_expected = []\n",
    "\n",
    "# Iterate through sample list and feed into word_value function defined above to\n",
    "# return the counts of the word in both high and low value questions\n",
    "for word in common_words:\n",
    "    observed_expected.append(word_value(word))\n",
    "\n",
    "# Empty list to store the chi_squared values.\n",
    "chi_squared = []\n",
    "\n",
    "# Iterate through observed counts, sum the observed counts, calculate the \n",
    "# proportion of observations to the total number of questions; then calculate\n",
    "# the expected proportions by multiplying the total proportion by the number of \n",
    "# high value questions and the number of low value questions.\n",
    "for observation in observed_expected:\n",
    "    total = sum(observation)\n",
    "    total_prop = total / jeopardy_sorted.shape[0]\n",
    "    high_value_expected = total_prop * high_value_count\n",
    "    low_value_expected = total_prop * low_value_count\n",
    "    expected = (high_value_expected,low_value_expected)\n",
    "    \n",
    "    values = chisquare(observation, expected)\n",
    "    chi_squared.append(values)\n",
    "    \n",
    "chi_squared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final result was 4 significant words in our list which are repeated more often than others. This technique could lead to finding more questions which should be studied, however, it may not yield many questions as this only yielded significant results when the word frequency was particularly high. \n",
    "\n",
    "We will stop the analysis here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
